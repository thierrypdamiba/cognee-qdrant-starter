# Disable multi-user access control (required for qdrant adapter)
ENABLE_BACKEND_ACCESS_CONTROL=false

# Qdrant Cloud
QDRANT_URL=<your-qdrant-cloud-url>
QDRANT_API_KEY=<your-qdrant-api-key>

# cognee vector store config
VECTOR_DB_PROVIDER=qdrant
VECTOR_DB_URL=<your-qdrant-cloud-url>
VECTOR_DB_KEY=<your-qdrant-api-key>
VECTOR_DB_NAME=cognee_db

# OpenAI for cognee LLM (or use alternatives below)
OPENAI_API_KEY=<your-openai-api-key>

# Ollama for embeddings (local, matches stored 768-dim vectors)
EMBEDDING_PROVIDER=ollama
EMBEDDING_MODEL=nomic-embed-text
EMBEDDING_DIMENSIONS=768
EMBEDDING_ENDPOINT=http://localhost:11434/api/embeddings
HUGGINGFACE_TOKENIZER=nomic-ai/nomic-embed-text-v1.5

# Alternative LLM configs (pick one)
# ---------------------------------

# Option A: OpenAI (default, uses OPENAI_API_KEY above)

# Option B: Local via Ollama
# LLM_PROVIDER=ollama
# LLM_MODEL=qwen3:4b
# LLM_ENDPOINT=http://localhost:11434/v1
# LLM_API_KEY=ollama

# Option C: OpenRouter (free models available)
# LLM_PROVIDER=custom
# LLM_MODEL=openrouter/google/gemini-2.0-flash-lite-preview-02-05:free
# LLM_ENDPOINT=https://openrouter.ai/api/v1
# LLM_API_KEY=<your-openrouter-key>
